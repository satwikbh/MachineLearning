import os
import json
import glob

from ete3 import Tree
from subprocess import Popen
from collections import defaultdict

from PrepareData.ParsingLogic import ParsingLogic
from HelperFunctions.Encoding import Encoding
from HelperFunctions.HelperFunction import HelperFunction


class PhylogeneticAnalysis:
    def __init__(self, log):
        self.log = log

        self.parser = ParsingLogic(use_trie_pruning=True)
        self.encoder = Encoding()
        self.helper = HelperFunction()

    @staticmethod
    def remove_scanning_key(md5_value_list, doc2bow):
        doc2bow_test = defaultdict(list)
        for md5_value in md5_value_list:
            doc2bow_test[md5_value] = doc2bow[md5_value]
            doc2bow.pop(md5_value)
        return doc2bow_test, doc2bow

    @staticmethod
    def load_pools(freq_individual_pool_path):
        meta_pool = list()
        pool_list = glob.glob(freq_individual_pool_path + "/" + "*.json")
        for indi_pool in pool_list:
            pool = json.load(open(indi_pool))
            meta_pool += pool
        return meta_pool

    def phylogenetic_analysis(self, **kwargs):
        """
        :param kwargs:
        :return:
        """
        clusters_db = kwargs['clusters_db']
        c2db_collection = kwargs['c2db_collection']
        family = kwargs['family']
        phylo_path = kwargs['phylo_path']
        iterative = kwargs['iterative']
        encoding_method = kwargs['encoding_method']
        target_list = kwargs['target_list']
        freq_individual_pool_path = kwargs['freq_individual_pool_path']

        meta_pool = self.load_pools(freq_individual_pool_path=freq_individual_pool_path)

        if family in clusters_db.collection_names():
            collection = clusters_db[family]
            cursor = collection.find({"md5": {"$exists": True}})
            list_of_keys = list()
            for doc in cursor:
                list_of_keys.append(doc["md5"])
            counter = 0
            iterator = 0
            chunk_size = 100
            doc2bow = defaultdict(list)
            while counter < len(list_of_keys):
                if counter + chunk_size < len(list_of_keys):
                    p_keys = list_of_keys[counter: counter + chunk_size]
                else:
                    p_keys = list_of_keys[counter:]
                list_of_docs = self.helper.convert_to_vs_keys(p_keys)
                p_doc2bow = self.parser.parse_each_document(collection=c2db_collection, list_of_docs=list_of_docs)
                for key, value in p_doc2bow.items():
                    val = [_ for _ in value if _ in meta_pool]
                    doc2bow[key] = val
                counter += chunk_size
                iterator += 1
            doc2bow_test, doc2bow = self.remove_scanning_key(target_list[0], doc2bow)
            sequence_list, key_list, meta_cluster_dict_len, meta_cluster_count_dict = self.sequence_alignment(
                doc2bow, doc2bow_test)
            meta_sequence, test_sequence = sequence_list[0], sequence_list[1]

            if iterative:
                fasta_file_name = self.add_sequence(phylo_path=phylo_path, encoding_method=encoding_method,
                                                    meta_cluster_count_dict=meta_cluster_count_dict,
                                                    meta_cluster_dict_len=meta_cluster_dict_len,
                                                    meta_sequence=meta_sequence, key_list=key_list,
                                                    iterative=iterative, target_list=doc2bow_test.keys(),
                                                    family=family, test_sequence=test_sequence)
            else:
                fasta_file_name = self.add_sequence(phylo_path=phylo_path, encoding_method=encoding_method,
                                                    meta_cluster_count_dict=meta_cluster_count_dict,
                                                    meta_cluster_dict_len=meta_cluster_dict_len,
                                                    meta_sequence=meta_sequence, key_list=key_list,
                                                    iterative=iterative, target_list=target_list,
                                                    family=family, test_sequence=test_sequence)
        else:
            self.log.error("The inferred family is not in the Database")
            fasta_file_name = None
        return fasta_file_name

    def get_all_children(self, node):
        leaf_list = []
        if node.is_leaf():
            leaf_list.append(node.name)
        else:
            children = node.get_children()
            for each in children:
                leaf_list += self.get_all_children(each)
        return leaf_list

    def get_sister_groups(self, tree_fname, num_sim_malware_retrieve, md5_list):
        """
        Takes the tree and loads into ete3 Tree class. Finds the target position in the Phylo tree.
        Retrieves its sister groups, children if they are present.
        :param tree_fname:
        :param num_sim_malware_retrieve: Will be added in future.
        :param md5_list:
        :return:
        """
        meta_node_dict = defaultdict()
        for md5_value in md5_list:
            try:
                node_dict = dict()
                children_nodes_list = list()
                sister_nodes_list = list()
                f = open(tree_fname, "r")
                tree = Tree(f.read())
                target_node = tree.search_nodes(name="VirusShare_" + str(md5_value))[0]
                children_nodes = target_node.get_children()
                if len(children_nodes) != 0:
                    for child_node in children_nodes:
                        children_nodes_list += self.get_all_children(child_node)

                sister_nodes = target_node.get_sisters()
                if len(sister_nodes) != 0:
                    for node in sister_nodes:
                        sister_nodes_list += self.get_all_children(node)

                node_dict['children'] = children_nodes_list
                node_dict['sisters'] = sister_nodes_list
            except Exception as e:
                self.log.error("Error : {}".format(e))
            meta_node_dict[md5_value] = node_dict
        return meta_node_dict

    def build_phylogeny_tree(self, fasta_fname, iterative, k_sim_malware_retrieve, md5_list):
        """
        Takes the fasta file path as input and then generates the phylogenetic tree.
        :param fasta_fname:
        :param iterative:
        :param k_sim_malware_retrieve:
        :param md5_list:
        :return:
        """
        self.log.info("Building phylogenetic tree")
        mafft_fname = fasta_fname.split(".")[0] + ".mafft"
        tree_fname = fasta_fname.split(".")[0] + ".phy"

        self.log.info("Invoking MAFFT as sub-process")
        if iterative:
            test_file_name = fasta_fname + "_add"
            mafft_subprocess = Popen([os.environ["mafft"], "--add", test_file_name, "--reorder", fasta_fname],
                                     stdout=open(mafft_fname, "w"))
        else:
            mafft_subprocess = Popen([os.environ["mafft"], fasta_fname], stdout=open(mafft_fname, "w"))
        self.log.info("MAFFT subprocess output : {}".format(mafft_subprocess.communicate()))

        self.log.info("Invoking FastTree as sub-process")
        fasttree_subprocess = Popen([os.environ["FastTree"], "-fastest", mafft_fname], stdout=open(tree_fname, "w"))
        self.log.info("FastTree subprocess output : {}".format(fasttree_subprocess.communicate()))

        meta_node_dict = self.get_sister_groups(tree_fname, k_sim_malware_retrieve, md5_list)
        return tree_fname, meta_node_dict

    def sequence_alignment(self, doc2bow, doc2bow_test):
        """
        Takes as input the doc2bow and then builds a meta_cluster.
        For each of the malware's features, it then creates a binary vector representation.
        The resultant output is the sequence in a coo_matrix format and row_index of the given malware.
        :param doc2bow:
        :param doc2bow_test:
        :return:
        """
        meta_cluster_count_dict = dict()
        meta_cluster_dict = defaultdict(list)
        meta_cluster_dict.default_factory = meta_cluster_dict.__len__

        meta_cluster = self.helper.flatten_list(doc2bow.values())
        for value in meta_cluster:
            meta_cluster_dict[value]
            if value in meta_cluster_count_dict:
                meta_cluster_count_dict[value] += 1
            else:
                meta_cluster_count_dict[value] = 1

        meta_sequence = list()
        meta_cluster_dict_len = len(meta_cluster_dict.keys())
        key_list = doc2bow.keys()
        for value in doc2bow.values():
            column = list(set([meta_cluster_dict[x] for x in value]))
            meta_sequence.append(column)

        if doc2bow_test is not None:
            test_cluster = self.helper.flatten_list(doc2bow_test.values())
            test_cluster = [x for x in test_cluster if x in meta_cluster_dict]

            test_sequence = list()
            for t_value in doc2bow_test.values():
                t_column = list(set([meta_cluster_dict[t_x] for t_x in t_value if t_x in test_cluster]))
                test_sequence.append(t_column)

        sequence_list = [meta_sequence, test_sequence]
        return sequence_list, key_list, meta_cluster_dict_len, meta_cluster_count_dict

    def with_encoding(self, **kwargs):
        """
        Creates a file for MSA which will be input for the MAFFT. Uses the old method where encoding is present.
        In case of building a new MSA file from scratch then it returns MSA filename and None.
        In case of adding a sequence to already existing MSA file then it returns MSA filename and Sequence filename.
        :param kwargs:
        :return:
        """
        meta_sequence = kwargs['meta_sequence']
        fasta_file_name = kwargs['fasta_fname']
        meta_cluster_dict_len = kwargs['meta_cluster_dict_len']
        iterative = kwargs['iterative']
        target_list = kwargs['target_list']
        key_list = kwargs['key_list']

        if iterative:
            test_sequence = kwargs['test_sequence']
            add_fasta_fname = fasta_file_name + "_add"
            add_fasta_file = open(add_fasta_fname, "w")
            for x in xrange(len(test_sequence)):
                test_list = meta_cluster_dict_len * ['0']
                for y in test_sequence[x]:
                    test_list[y] = '1'
                test_str = "".join(map(str, test_list))
                test_str = self.encoder.encode(test_str)
                print >> add_fasta_file, ">" + str(target_list[x]), "\n", test_str
            add_fasta_file.close()

        main_fasta_file = open(fasta_file_name, "w")
        for x in xrange(len(meta_sequence)):
            meta_list = meta_cluster_dict_len * ['0']
            for y in meta_sequence[x]:
                meta_list[y] = '1'
            meta_str = "".join(map(str, meta_list))
            meta_str = self.encoder.encode(meta_str)
            print >> main_fasta_file, ">" + str(key_list[x]), "\n", meta_str
        main_fasta_file.close()

        return fasta_file_name, add_fasta_fname

    def without_encoding(self, **kwargs):
        """
        Creates a file for MSA which will be input for the MAFFT. It uses the new method where there is no encoding.
        In case of building a new MSA file from scratch then it returns MSA filename and None.
        In case of adding a sequence to existing MSA file then it returns MSA filename and the Sequence filename.
        :param kwargs:
        :return:
        """
        meta_cluster_count_dict = kwargs['meta_cluster_count_dict']
        meta_sequence = kwargs['meta_sequence']
        fasta_file_name = kwargs['fasta_file_name']
        meta_cluster_dict_len = kwargs['meta_cluster_dict_len']
        iterative = kwargs['iterative']
        target_list = kwargs['target_list']
        key_list = kwargs['key_list']

        # threshold = np.mean(meta_cluster_count_dict.values())
        # col_index_del = [index for index, value in enumerate(meta_cluster_count_dict.values()) if
        #                  value < threshold]

        if iterative:
            test_sequence = kwargs['test_sequence']  # This cannot be None if iterative is True.
            add_fasta_fname = fasta_file_name + "_add"
            add_file = open(add_fasta_fname, "w")
            target_list = self.helper.convert_to_vs_keys(target_list)
            for x in xrange(len(test_sequence)):
                test_list = meta_cluster_dict_len * ['N']
                for y in test_sequence[x]:
                    test_list[y] = 'M'
                # test_list = np.delete(test_list, col_index_del)
                print >> add_file, ">" + str(target_list[x]), "\n", "".join(map(str, test_list))
            add_file.close()
        else:
            add_fasta_fname = None

        main_fasta_file = open(fasta_file_name, "w")
        for x in xrange(len(meta_sequence)):
            meta_list = meta_cluster_dict_len * ['N']
            for y in meta_sequence[x]:
                meta_list[y] = 'M'
            # meta_list = np.delete(meta_list, col_index_del)
            print >> main_fasta_file, ">" + str(key_list[x]), "\n", "".join(map(str, meta_list))
        main_fasta_file.close()

        return fasta_file_name, add_fasta_fname

    def add_sequence(self, **kwargs):
        """
        :param kwargs:
        :return:
        """
        phylo_path = kwargs['phylo_path']
        encoding_method = kwargs['encoding_method']
        meta_cluster_count_dict = kwargs['meta_cluster_count_dict']
        meta_cluster_dict_len = kwargs['meta_cluster_dict_len']
        meta_sequence = kwargs['meta_sequence']
        iterative = kwargs['iterative']
        family = kwargs['family']
        test_sequence = kwargs['test_sequence']
        target_list = kwargs['target_list']
        key_list = kwargs['key_list']

        if encoding_method == 'old':
            fasta_file_name = phylo_path + "/" + str(family) + "_with_enc" + ".fasta"
            fasta_file_name, add_fasta_fname = self.with_encoding(meta_sequence=meta_sequence,
                                                                  fasta_fname=fasta_file_name,
                                                                  meta_cluster_dict_len=meta_cluster_dict_len,
                                                                  iterative=iterative,
                                                                  target_list=target_list,
                                                                  key_list=key_list,
                                                                  test_sequence=test_sequence)
        elif encoding_method == 'new':
            fasta_file_name = phylo_path + "/" + str(family) + "_wo_enc" + ".fasta"
            fasta_file_name, add_fasta_fname = self.without_encoding(
                meta_cluster_count_dict=meta_cluster_count_dict,
                meta_cluster_dict_len=meta_cluster_dict_len,
                meta_sequence=meta_sequence,
                fasta_file_name=fasta_file_name,
                iterative=iterative,
                target_list=target_list,
                key_list=key_list,
                test_sequence=test_sequence)
        else:
            self.log.error("Encoding specified is not recognized")
            fasta_file_name = None
        return fasta_file_name
